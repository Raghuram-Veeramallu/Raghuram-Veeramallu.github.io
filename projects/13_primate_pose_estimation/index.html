<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Primate Pose Estimation | Hari Veeramallu</title> <meta name="author" content="Hari Sai Raghuram Veeramallu"> <meta name="description" content="Designed a deep learning model using rCNNs and CPM for the OpenMonkeyChallenge to estimate monkey poses in natural habitats. It tracks 17 monkey pose landmarks, with its accuracy measured by MPJPE. The model achieved an MPJPE of 0.217, enhancing wildlife monitoring and behavioral studies through AI."> <meta name="keywords" content="jekyll, jekyll-theme, hari-portolfio ,portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logo.png"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://raghuram-veeramallu.github.io/projects/13_primate_pose_estimation/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="//"> Hari Veeramallu</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Primate Pose Estimation</h1> <p class="post-description">Designed a deep learning model using rCNNs and CPM for the OpenMonkeyChallenge to estimate monkey poses in natural habitats. It tracks 17 monkey pose landmarks, with its accuracy measured by MPJPE. The model achieved an MPJPE of 0.217, enhancing wildlife monitoring and behavioral studies through AI.</p> </header> <article> <p>This project aims at estimating the pose of Non-Human Primates (NHP) in different environment settings. This projects particularly aims to approach the <a href="http://openmonkeychallenge.com/" rel="external nofollow noopener" target="_blank">OpenMonkeyChallenge</a>. OpenMonkeyChallenge is a computer vision benchmark challenge for NHP pose estimation. The data for this challenge consists of over 100,000 annotated photographs of NHPs in naturalistic contexts obtained from various sources for various species of monkeys and apes. The pose of the monkey is determined by 17 key pose landmarks including Nose, Left eye, Right eye, Head, Neck, Left shoulder, Left elbow, Left wrist, Right shoulder, Right elbow, Right wrist, Hip, Left knee, Left ankle, Right knee, Right ankle, and Tail. The dataset has been made publicly available by <a href="https://link.springer.com/article/10.1007/s11263-022-01698-2" rel="external nofollow noopener" target="_blank">Yao et. Al.</a>.</p> <p>This project has been taken as part of Computer Vision (University of Minnesota, Fall 2022) coursework under <a href="https://junaedsattar.cs.umn.edu/" rel="external nofollow noopener" target="_blank">Dr. Junaed Sattar</a>.</p> <p><a href="https://portfolio-rv.s3.amazonaws.com/resume/project-papers/non-human-primate-pose-estimation.pdf" rel="external nofollow noopener" target="_blank">Project Report</a></p> <div class="row"> <div class="col-sm-6 mt-3 mt-md-0"> <figure class="col4" style="height: 100%; display: flex; align-items: center; justify-content: center;"> <picture style="height: 100%; width: 100%;"> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/nppe_data_distr-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/nppe_data_distr-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/nppe_data_distr-1400.webp"></source> <img src="/assets/img/nppe_data_distr.png" class="img-fluid rounded z-depth-1" title="Data Distribution" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-6 mt-3 mt-md-0"> The OpenMonkeyChallenge provides a diverse dataset of 111,529 annotated images of 26 species (6 New World monkeys, 14 Old World monkeys, and 6 apes) of non-human primates in natural contexts with 17 landmark annotations. <br> <br> This dataset is split into training, validation and test datasets (60%, 20%, and 20% respectively) </div> </div> <div class="caption col-sm-6 mt-3 mt-md-0"> Distribution of the data </div> <p>The baseline for my method is based upon <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Wei_Convolutional_Pose_Machines_CVPR_2016_paper.pdf" rel="external nofollow noopener" target="_blank">Wei et. al.</a> who use the Convolutional Pose Machine (CPM) to estimate the landmark locations in humans. CPM is divied into 3 stages that generate 18 belief images (17 for landmarks + 1 for background). These belief images convey the confidence that a landmark is at a location.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure class="col4" style="height: 100%; display: flex; align-items: center; justify-content: center;"> <picture style="height: 100%; width: 100%;"> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/nppe_architecture-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/nppe_architecture-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/nppe_architecture-1400.webp"></source> <img src="/assets/img/nppe_architecture.png" class="img-fluid rounded z-depth-1" title="Architecure" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Architecture: rCNN-CPM based architecture </div> <p>The diverse anatomy and behaviour of non-human primate species make generalizing the relationships between image and context features for pose estimation difficult. To handle the differences between species I trained a CPM on each class of the monkey species (Old World, New World and Ape). Non-human primates are classified into one of the classes using a rCNN, and the corresponding CPM will estimate the landmark locations for that species.</p> <div class="row"> <div class="col-sm mt-5 mt-md-0"> <figure class="col4" style="height: 100%; display: flex; align-items: center; justify-content: center;"> <picture style="height: 100%; width: 100%;"> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/nppe_landmark1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/nppe_landmark1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/nppe_landmark1-1400.webp"></source> <img src="/assets/img/nppe_landmark1.png" class="img-fluid rounded z-depth-1" title="landmark" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-5 mt-md-0"> <figure class="col4" style="height: 100%; display: flex; align-items: center; justify-content: center;"> <picture style="height: 100%; width: 100%;"> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/nppe_landmark2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/nppe_landmark2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/nppe_landmark2-1400.webp"></source> <img src="/assets/img/nppe_landmark2.png" class="img-fluid rounded z-depth-1" title="landmark" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-5 mt-md-0"> <figure class="col4" style="height: 100%; display: flex; align-items: center; justify-content: center;"> <picture style="height: 100%; width: 100%;"> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/nppe_landmark3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/nppe_landmark3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/nppe_landmark3-1400.webp"></source> <img src="/assets/img/nppe_landmark3.png" class="img-fluid rounded z-depth-1" title="landmark" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-5 mt-md-0"> <figure class="col4" style="height: 100%; display: flex; align-items: center; justify-content: center;"> <picture style="height: 100%; width: 100%;"> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/nppe_landmark4-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/nppe_landmark4-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/nppe_landmark4-1400.webp"></source> <img src="/assets/img/nppe_landmark4.png" class="img-fluid rounded z-depth-1" title="landmark" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-5 mt-md-0"> <figure class="col4" style="height: 100%; display: flex; align-items: center; justify-content: center;"> <picture style="height: 100%; width: 100%;"> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/nppe_landmark5-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/nppe_landmark5-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/nppe_landmark5-1400.webp"></source> <img src="/assets/img/nppe_landmark5.png" class="img-fluid rounded z-depth-1" title="landmark" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Landmark Location Estimations. The blue X’s are the ground truth locations and the red circles are our estimated locations. This method can reasonably estimate the landmark locations for a variety of non-human primate species and poses. </div> <p>The proposed and baseline method’s efficacy in detecting the poses of the images were evaluated based on its <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Iskakov_Learnable_Triangulation_of_Human_Pose_ICCV_2019_paper.pdf" rel="external nofollow noopener" target="_blank">MPJPE</a> and <a href="https://escholarship.org/content/qt7sk1s10g/qt7sk1s10g_noSplash_a8d7d492292a22ca3c20c0c99cbd9d1f.pdf?t=oub9r6" rel="external nofollow noopener" target="_blank">PCK</a>. Overall, the model achieves comparable overall performance to the baseline. Additionally, the model gave better results for Apes and New World monkeys but could not outperform the baseline for Old World monkeys.</p> <p>The performance of our method could be further improved by performing additional data augmentation to limit the number of poor training samples (multiple or occluded non-human primates). Additionally, the number of stages in each CPM could be raised to increase the range of learned context features. Finally, more samples of New World Monkeys and Apes could be added so that Old World Monkeys do not dominate the dataset.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Hari Veeramallu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. © Photos copyright Hari Veeramallu. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-006L5ZSDNF"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-006L5ZSDNF");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>